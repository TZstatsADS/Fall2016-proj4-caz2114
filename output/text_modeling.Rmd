---
title: "Topic Modelling"
date: "11/9/2016"
output: html_document
---  
###This will downloard the LAvisData package if not installed
```{r setup}
install.packages("devtools")
devtools::install_github("cpsievert/LDAvisData")

```

```{r setup}
library("LDAvisData", lib.loc="~/R/win-library/3.3")
data(reviews, package = "LDAvisData")

library(NLP)
library(tm)
library(lda)
library(LDAvis)
```

##### Pre-processing  
```{r}
word_freq <- colSums(lyr[,-1])
word_freq <- sort(word_freq, decreasing = TRUE)
head(word_freq)
```

Term table is a table of ALL terms that exist in our collections of documents. Here we still see words that do not bear much information, so we move on to delete them.

**dictionar: all distinct words**  
```{R}
directory <- names(word_freq)  #this is 1x5000
```

**"Now put the documents into the format required by the lda package"**
```{R}
# now put the documents into the format required by the lda package:
setwd("C:/Users/CATHY/OneDrive/Documents/2016-2017 Junior/Applied Data Science/Project 4/Fall2016-Proj4-caz/data")
h5file_path <- list.files(path = "./", recursive = TRUE)
setwd("C:/Users/CATHY/OneDrive/Documents/2016-2017 Junior/Applied Data Science/Project 4/Fall2016-Proj4-caz/Data")

lyric_song<-vector(mode = "list",length = length(lyr)-1)

combine <- function(x) {
  index <- grepl(x, lyr[,1])
  non_zero <- lyr[index,which(lyr[index,]>0)]
  index <- match(colnames(non_zero)[-1],directory)
  index <- index[!is.na(index)]
  hi<-rbind(as.integer(index),as.integer(non_zero[-1]))
}

lyric_song<-lapply(lyr[,1],combine)
names(lyric_song) <- lyr[,1]
save(lyric_song,file = "lyric_song.RData")
```


**"Turning parameters"**
```{r}
# MCMC and model tuning parameters:
K <- 20
G <- 5000
alpha <- 0.02
eta <- 0.02
```


```{R,eval=FALSE}
# Fit the model:
library(lda)
set.seed(357)
t1 <- Sys.time()
fit <- lda.collapsed.gibbs.sampler(documents = lyric_song, K = K, vocab = directory, 
                                   num.iterations = G, alpha = alpha, 
                                   eta = eta, initial = NULL, burnin = 0,
                                   compute.log.likelihood = TRUE)
t2 <- Sys.time()
t2 - t1 #runtime 13 min 


save(fit,file = "fit.RData")
#now can acces
```


##### Visualization  
```{R,eval=FALSE}
theta <- t(apply(fit$document_sums + alpha, 2, function(x) x/sum(x)))
phi <- t(apply(t(fit$topics) + eta, 2, function(x) x/sum(x)))

MovieReviews <- list(phi = phi,
                     theta = theta,
                     doc.length = doc.length,
                     vocab = vocab,
                     term.frequency = term.frequency)
library(servr)
# create the JSON object to feed the visualization:
json <- createJSON(phi = MovieReviews$phi, 
                   theta = MovieReviews$theta, 
                   doc.length = MovieReviews$doc.length, 
                   vocab = MovieReviews$vocab, 
                   term.frequency = MovieReviews$term.frequency)

serVis(json, out.dir = 'vissample', open.browser = FALSE)
```

```{r,include=FALSE,eval=FALSE}
# 1. separate logistics  
# 2. Naive bayes  
# 3. Tree structure, generative, create music vocabulary; association mining  
# 4. Topic modelling: use features to predict topic profiles and then generate words
```